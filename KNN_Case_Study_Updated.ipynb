{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "zhTCtv5cNuAY",
        "Fi4-2byijgkD",
        "4tv-K5MIkATV",
        "RhNULb3ysdiS"
      ],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/tripathiosho/ImportantNotebooks/blob/main/KNN_Case_Study_Updated.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Obesity Dataset with k-Nearest Neighbors\n",
        "\n",
        "\n",
        "## Context\n",
        "\n",
        "Welcome to the **Scaler Healthcare** data analysis team! As part of our ongoing efforts to understand and combat obesity globally, we're leveraging data to gain insights into factors contributing to obesity. You've been tasked with analyzing the Obesity Dataset, applying the k-Nearest Neighbors (kNN) algorithm to predict obesity levels based on individuals' eating habits and physical conditions.\n",
        "\n",
        "## Dataset Description\n",
        "\n",
        "The dataset you'll be working with contains attributes related to individuals' eating habits and physical conditions. Here's a breakdown of the features you'll encounter:\n",
        "\n",
        "### Eating Habits Attributes:\n",
        "1. **FAVC (Frequent consumption of high caloric food):** Indicates if the individual frequently eats high caloric food.\n",
        "2. **FCVC (Frequency of consumption of vegetables):** Reflects how often the individual consumes vegetables.\n",
        "3. **NCP (Number of main meals):** Represents the number of main meals the individual has in a day.\n",
        "4. **CAEC (Consumption of food between meals):** Shows how frequently the individual eats between meals.\n",
        "5. **CH20 (Consumption of water daily):** Details the daily water consumption.\n",
        "6. **CALC (Consumption of alcohol):** Provides information on the individual's alcohol consumption.\n",
        "\n",
        "### Physical Condition Attributes:\n",
        "7. **SCC (Calories consumption monitoring):** Indicates if the individual monitors their calorie intake.\n",
        "8. **FAF (Physical activity frequency):** Reflects the frequency of physical activity.\n",
        "9. **TUE (Time using technology devices):** Denotes the time spent using technology devices.\n",
        "10. **MTRANS (Transportation used):** Details the primary mode of transportation."
      ],
      "metadata": {
        "id": "QwpDFGucilPa"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kuzPYa-cgZCl"
      },
      "outputs": [],
      "source": [
        "# Downloading the Dataset\n",
        "!wget https://d2beiqkhq929f0.cloudfront.net/public_assets/assets/000/070/840/original/ObesityDataSet.csv"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "df = pd.read_csv(\"ObesityDataSet.csv\")\n",
        "df.head()"
      ],
      "metadata": {
        "id": "UbXez_F8glj2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "\n",
        "# KNN Lecture-1 Assesments"
      ],
      "metadata": {
        "id": "zhTCtv5cNuAY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "\n",
        "## Analyzing Skewness in the Obesity Dataset\n",
        "\n",
        "### Context\n",
        "You are tasked with exploring the Obesity dataset to understand the distribution of various features, especially focusing on skewness. This analysis is crucial for applying the kNN algorithm effectively.\n",
        "\n",
        "### Dataset\n",
        "The dataset includes attributes related to individuals' eating habits and physical conditions. You'll examine these features to identify any right-skewness and explore the relationship between the **mean, median, and mode** for those features.\n",
        "\n",
        "### Task\n",
        "Your goal is to perform Exploratory Data Analysis (EDA) to identify which of the given features are right-skewed. For any right-skewed feature, you should determine how the mean, median, and mode relate to each other.\n",
        "\n",
        "### Instructions\n",
        "1. Load the dataset.\n",
        "2. Conduct EDA focusing on the skewness of the attributes.\n",
        "3. Identify any right-skewed features.\n",
        "4. For each right-skewed feature, analyze the relationship between the mean, median, and mode.\n",
        "\n",
        "\n",
        "Complete the code template below to analyze the skewness of the features and understand the distribution of the dataset. Once you have identified the right-skewed features, calculate and print the mean, median, and mode for each to observe their relationship."
      ],
      "metadata": {
        "id": "Fi4-2byijgkD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "for feature in df.columns:\n",
        "    # Skipping non-numeric features for histogram plotting\n",
        "    if df[feature].dtype == _____:\n",
        "        continue\n",
        "\n",
        "    # Calculate mean, median, and mode\n",
        "    mean = df[feature].____()  # Fill in the blank to calculate mean\n",
        "    median = df[feature].____()  # Fill in the blank to calculate median\n",
        "    mode = df[feature].____().get(0, np.nan)  # Fill in the blank to calculate mode\n",
        "\n",
        "    # Create the histogram\n",
        "    plt.figure(figsize=(10, 6))\n",
        "    df[feature].hist(bins=20, alpha=0.7)\n",
        "\n",
        "    # Add lines for mean, median, and mode\n",
        "    plt.axvline(____, color='red', linestyle='dashed', linewidth=2)  # Fill in the blank to plot mean\n",
        "    plt.axvline(____, color='green', linestyle='dashed', linewidth=2)  # Fill in the blank to plot median\n",
        "    plt.axvline(____, color='blue', linestyle='dashed', linewidth=2)  # Fill in the blank to plot mode\n",
        "\n",
        "    # Add annotations for mean, median, and mode\n",
        "    plt.text(____, plt.ylim()[1] * 0.95, f'Mean: {mean:.2f}', color = 'red')  # Fill in the blank to annotate mean\n",
        "    plt.text(____, plt.ylim()[1] * 0.90, f'Median: {median:.2f}', color = 'green')  # Fill in the blank to annotate median\n",
        "    plt.text(____, plt.ylim()[1] * 0.85, f'Mode: {mode:.2f}', color = 'blue')  # Fill in the blank to annotate mode\n",
        "\n",
        "    # Add title and labels\n",
        "    plt.title(f'Histogram of {feature}')\n",
        "    plt.xlabel(feature)\n",
        "    plt.ylabel('Frequency')\n",
        "\n",
        "    # Show the plot\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "H3h8DLSTmFc_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n",
        "## Analyzing Feature Interactions in the Obesity Dataset\n",
        "\n",
        "### Context:\n",
        "After exploring individual feature distributions in the Obesity dataset, your next objective is to examine the interactions between these features. Understanding the relationships between different features can provide insights into the dataset's structure and inform the feature selection process, especially for machine learning algorithms that are sensitive to multicollinearity, such as kNN.\n",
        "\n",
        "### Task:\n",
        "Your task is to create and analyze a correlation matrix for the numerical features in the Obesity dataset. This matrix will help you identify how different features are related and determine if there are any pairs of features that exhibit a high degree of correlation.\n",
        "\n",
        "### Instructions:\n",
        "1. Compute the correlation matrix for the numerical features in the Obesity dataset.\n",
        "2. Visualize this correlation matrix using a heatmap to make it easier to identify relationships between features.\n",
        "3. Analyze the heatmap to pinpoint any notable feature correlations. Pay particular attention to features with high correlation coefficients, as these relationships are particularly impactful.\n",
        "\n",
        "### Question:\n",
        "Based on your correlation matrix analysis for the Obesity dataset, identify one pair of features that exhibit a high degree of correlation. Describe how this finding could influence the feature selection process for a kNN model. What might be the implications of including both of these highly correlated features in your kNN model?"
      ],
      "metadata": {
        "id": "4tv-K5MIkATV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import seaborn as sns\n",
        "\n",
        "# Compute the correlation matrix for numerical features\n",
        "correlation_matrix = df.select_dtypes(include=[np.number]).____()  # Fill in the blank to compute correlation\n",
        "\n",
        "# Visualize the correlation matrix using a heatmap\n",
        "plt.figure(figsize=(10, 8))\n",
        "sns.heatmap(____, annot=True, fmt=\".2f\", cmap='coolwarm')  # Fill in the blank to plot the heatmap\n",
        "\n",
        "# Show the plot\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "VzZKE7uTkfpR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "---\n",
        "## Covariance vs Correlation\n",
        "#### Context:\n",
        "In the field of statistics and data science, grasping the differences between covariance and correlation is crucial for analyzing relationships between two variables. Both metrics serve to indicate how variables change together, yet they offer distinct perspectives and interpretative values.\n",
        "#### Question:\n",
        "Which of the following statements correctly defines covariance and correlation?\n",
        "#### Statements to Evaluate:\n",
        "S1: Covariance measures how two variables change together, but its value is influenced by the scale of the variables, making it hard to interpret the strength of their relationship.\n",
        "\n",
        "S2: Correlation is a normalized measure of covariance, providing a dimensionless value that indicates the strength and direction of a linear relationship.\n",
        "\n",
        "S3: Correlation measures both linear and non-linear relationships between variables.\n",
        "\n",
        "S4: Covariance and correlation both provide identical information about the direction and strength of the relationship between variables.\n",
        "\n",
        "#### **Options:**\n",
        "A) S1 and S2\n",
        "\n",
        "\n",
        "B) S1 and S3\n",
        "\n",
        "C) S2 and S4\n",
        "\n",
        "D) S3 and S4"
      ],
      "metadata": {
        "id": "WJ8SFarAmpiK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "## Select NearestNeighbor\n",
        "\n",
        "#### Question\n",
        "\n",
        "<p>Suppose you are using kNN with k = 1 and have 2 features: height and weight. Then what will be the class for the query point  ?</p>\n",
        "<p><img src=\"https://d2beiqkhq929f0.cloudfront.net/public_assets/assets/000/067/632/original/Screenshot_2024-03-01_at_11.23.08_AM.png?1709993067\" alt=\"\" width=\"473\" height=\"338\" /></p>\n",
        "\n",
        "#### Options\n",
        "A) Normal Weight\n",
        "\n",
        "B) Obesity_Type_II\n",
        "\n",
        "C) Either Normal Weight or Obesity_Type_II\n",
        "\n",
        "D) Cannot be Determined\n",
        "\n",
        "Note: **Select the correct option in the question link**"
      ],
      "metadata": {
        "id": "IuyZYropnpJk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n",
        "## Know about kNN\n",
        "\n",
        "#### Question\n",
        "As kNN is a Non-parametric Algorithm, when is it helpful ?\n",
        "\n",
        "#### Options\n",
        "A) Nonparametric methods are commonly used when we want a few assumptions in our data\n",
        "\n",
        "B) Nonparametric methods are commonly used when we want a lot of assumptions in our data\n",
        "\n",
        "C) Nonparametric methods are commonly used when we want outliers in data\n",
        "\n",
        "D) None of the above\n",
        "\n",
        "\n",
        "Note: **Select the correct option in the question link**"
      ],
      "metadata": {
        "id": "9Jv1W0pXoKCO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "\n",
        "## Know your data\n",
        "\n",
        "#### Context:\n",
        "Effective data analysis often requires identifying which features in a dataset contain the most outliers and which have the largest range of values. This insight is crucial for optimizing machine learning algorithms, particularly those like kNN, which are sensitive to outliers and the scale of data.\n",
        "\n",
        "#### Task:\n",
        "Determine which feature in our dataset has:  \n",
        "1. The highest number of outliers and\n",
        "2. The largest range of values.\n",
        "\n",
        "These characteristics are key to understanding data distribution and preparing for accurate modeling."
      ],
      "metadata": {
        "id": "aVQwIs5RrakK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sns._____(data = df) # Select plot that is useful in visualizing the distribution\n",
        "plt.show() is your"
      ],
      "metadata": {
        "id": "m3mBhBqrrn-L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "## Euclidean Distance code\n",
        "\n",
        "#### Context:\n",
        "Understanding the concept of Euclidean distance is essential in machine learning, particularly in algorithms like kNN. This distance measure plays a crucial role in determining the similarity between data points.\n",
        "\n",
        "#### Task:\n",
        "Write Python code to standardize a dataset and calculate the Euclidean distance between the first and last data points using specific features. This exercise will help you grasp the practical application of Euclidean distance in data preprocessing and similarity measurement.\n",
        "\n",
        "#### Instructions:\n",
        "1. Select the subset of the entire dataset with only two features 'FCVC' and 'FAF.\n",
        "2. Use `StandardScaler` to standardize this subset dataset.\n",
        "3. Define a function to calculate the Euclidean distance between two data points using the 'FCVC' and 'FAF' features.\n",
        "4. Calculate the Euclidean distance between the first and last data points in the entire scaled dataset.\n",
        "\n",
        "#### Question:\n",
        "After standardizing the dataset and calculating the Euclidean distance between the first and last data points using 'FCVC' and 'FAF' features, within what range does the calculated distance fall?\n"
      ],
      "metadata": {
        "id": "WtabOS7Vo6E6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "from math import sqrt\n",
        "\n",
        "def calculate_euclidean_distance(data_point1, data_point2):\n",
        "    distance = _____((data_point1['FCVC'] - data_point2['FCVC'])**2 + (_____))  # Try to remember the formula for euclidean distance\n",
        "    return distance\n",
        "\n",
        "df_scaler = StandardScaler()\n",
        "scaled_data = df_scaler.fit_transform(df[['FCVC', 'FAF']])\n",
        "scaled_data_df = pd.DataFrame(scaled_data, columns = ['FCVC', 'FAF'])\n",
        "\n",
        "# Select the first and last data point\n",
        "first_data_point = scaled_data_df.iloc[__]\n",
        "last_data_point = scaled_data_df.iloc[__]\n",
        "\n",
        "# Calculate the Euclidean distance between the first and last data points\n",
        "distance = calculate_euclidean_distance(first_data_point, last_data_point)\n",
        "print(distance)"
      ],
      "metadata": {
        "id": "BhqwOAuckngZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "## Implementing kNN code\n",
        "\n",
        "\n",
        "#### Context:\n",
        "You're provided with a Python script implementing the k-Nearest Neighbors (kNN) algorithm from scratch. This script includes functions for calculating Euclidean distance and predicting the label of a new data point based on a set of labeled data. You'll fill in the missing parts of the code to make it functional.\n",
        "\n",
        "#### Task:\n",
        "Complete the provided Python code by filling in the blanks to enable the kNN algorithm to predict the label of a new data point based on 'Gender', 'Age', 'Height', and 'Weight'.\n",
        "\n",
        "#### Question:\n",
        "After completing and executing the code , what label does the kNN algorithm predict?\n",
        "\n",
        "\n",
        "#### Fun Activity:\n",
        "Try inputting your age, gender, height, and weight into the new data point and run the code to see what label the kNN algorithm predicts for you."
      ],
      "metadata": {
        "id": "8g8nj-6arF0l"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "original_df = df.copy()"
      ],
      "metadata": {
        "id": "P5NwnhtAsWQv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
        "from math import sqrt\n",
        "from collections import Counter\n",
        "\n",
        "# Function to calculate Euclidean distance\n",
        "def euclidean_distance(row1, row2):\n",
        "    distance = 0.0\n",
        "    for i in range(len(row1)):\n",
        "        distance += (row1[i] - row2[i]) ** 2\n",
        "    return _________(distance)  # Hint: Final distance formula calculation step\n",
        "\n",
        "# Function to predict the label of a new data point\n",
        "def predict_label(train_data, new_data_point, num_neighbors):\n",
        "    distances = []\n",
        "    for _, row in train_data.iterrows():\n",
        "        dist = __________(new_data_point, row[:-1])  # Hint: Calculate distance\n",
        "        distances.append((row, dist))\n",
        "    distances.sort(key=lambda tup: tup[1])\n",
        "    neighbors = [dist[0] for dist in ___________[:num_neighbors]]  # Hint: Neighbors selection\n",
        "\n",
        "    output_values = [row[-1] for row in neighbors]\n",
        "    prediction = __________(set(output_values), key=output_values.count)  # Hint: Determine majority using Counter\n",
        "\n",
        "    return prediction\n",
        "\n",
        "# Encoding the 'Gender' column\n",
        "label_encoder = LabelEncoder()\n",
        "original_df['Gender'] = label_encoder.___________(original_df['Gender'])  # Hint: Fit and apply encoding\n",
        "\n",
        "# Scaling the features\n",
        "scaler = StandardScaler()\n",
        "original_df[['Age', 'Height', 'Weight']] = scaler.fit_transform(original_df[['Age', 'Height', 'Weight']])\n",
        "\n",
        "# New data point\n",
        "new_data = {'Gender': 'Male', 'Age': 32, 'Height': 175, 'Weight': 75}\n",
        "new_data_df = pd.DataFrame([new_data])\n",
        "\n",
        "# Encoding and scaling the new data point\n",
        "new_data_df['Gender'] = label_encoder.____________(new_data_df['Gender'])  # Hint: Apply existing encoding\n",
        "new_data_scaled = scaler.___________(new_data_df[['Age', 'Height', 'Weight']])  # Hint: Apply existing scaling\n",
        "\n",
        "new_data_point = [new_data_df['Gender'].iloc[0]] + new_data_scaled.tolist()[0]\n",
        "\n",
        "# Predicting the label\n",
        "predicted_label = predict_label(original_df, new_data_point, 5)\n",
        "print(f\"The predicted label is: {predicted_label}\")"
      ],
      "metadata": {
        "id": "Rl8dZ-oHqp3L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "rsqs7AHLYQCl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "_vs5zhPkYQAu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "dE4fi2ETYP-K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n",
        "# KNN Lecture-2 Assesments"
      ],
      "metadata": {
        "id": "RhNULb3ysdiS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Scaling in kNN\n",
        "\n",
        "#### Question:\n",
        "Select the statements which are correct regarding the importance of scaling in kNN:\n",
        "\n",
        "#### Statements:\n",
        "S1: Scaling is important in kNN because it ensures that all features contribute equally to the distance computation.\n",
        "\n",
        "S2: Unscaled features can disproportionately influence the distance calculations, affecting the performance of kNN.\n",
        "\n",
        "S3: Scaling prevents features from having negative values.\n",
        "\n",
        "S4: Scaling decreases the sample size of our data.\n",
        "\n",
        "#### Options\n",
        "A]  S1 and S2\n",
        "\n",
        "B]     S1, S2, and S3\n",
        "\n",
        "C]    S2 and S4\n",
        "\n",
        "D]    S1, S2, and S4\n",
        "\n",
        "Note: **Select the correct option in the question link**"
      ],
      "metadata": {
        "id": "hlFS83PDszFJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "## Predicting kNN Model Accuracy\n",
        "\n",
        "\n",
        "#### Context:\n",
        "You're tasked with implementing a k-Nearest Neighbors (kNN) classifier to predict a target variable in a dataset. Before diving into the code, it's crucial to understand the preprocessing steps involved, such as label encoding and feature scaling, which can significantly impact the model's performance.\n",
        "\n",
        "#### Objective:\n",
        "Write a Python script to preprocess the data, train a kNN model, and predict its test accuracy. You will use label encoding for categorical features and standard scaling for numerical features before training the model.\n",
        "\n",
        "#### Instructions:\n",
        "1. **Label Encoding:**\n",
        "\t- Apply label encoding to convert all categorical features into numeric values. Use `LabelEncoder` from `sklearn.preprocessing` for this task.\n",
        "\n",
        "2. **Feature and Target Selection:**\n",
        "\t- Separate your features (`X`) and target variable (`y`).\n",
        "\n",
        "3. **Data Splitting:**\n",
        "\t- Split the data into training and testing sets using `train_test_split` from `sklearn.model_selection`. Set `test_size` to 0.33 and `random_state` to 42.\n",
        "\n",
        "4. **Feature Scaling:**\n",
        "\t- Standardize the features using `StandardScaler` from `sklearn.preprocessing`. Fit the scaler on the training set and transform both the training and testing sets.\n",
        "\n",
        "5. **Model Training:**\n",
        "\t- Initialize and train a `KNeighborsClassifier` from `sklearn.neighbors` with default parameters. Fit the model on the scaled training data.\n",
        "\n",
        "6. **Model Evaluation:**\n",
        "\t- Evaluate the model's accuracy on the scaled test set using the `score` method and print the result.\n",
        "\n",
        "#### Question:\n",
        "After writing and executing the code, within what range does the kNN model's test accuracy fall?\n"
      ],
      "metadata": {
        "id": "qas3yx9btVCS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "\n",
        "# Apply label encoding\n",
        "label_encoder = LabelEncoder()\n",
        "for column in df.select_dtypes(_____).columns: # Hint: Select only object columns\n",
        "    df[column] = label_encoder._______(df[column]) # Hint: fit and transform the categorical column.\n",
        "\n",
        "X = df.iloc[:, :-1]  # Features\n",
        "y = df.iloc[:, -1]   # Target variable\n",
        "\n",
        "# Split the data using train_test_split function\n",
        "X_train, ____, ____, y_test = train_test_split(___, y, _____=0.33, random_state=42)\n",
        "\n",
        "# Standardize the features\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler._____(X_train) # Hint: fit and transform the X_train data.\n",
        "X_test_scaled = scaler._____(____) # Hint: only transform the X_test data.\n",
        "\n",
        "# Train the kNN model\n",
        "knn = KNeighborsClassifier()\n",
        "knn.fit(_____, ) # Hint: Fit the model using X scaled and y_train.\n",
        "\n",
        "# Print the accuracy\n",
        "print(knn.score(X_test_scaled, _____)) # Hint: check the accuracy on test dataset."
      ],
      "metadata": {
        "id": "yFXrvqApsTfT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n",
        "## kNN - Distance Metrics\n",
        "\n",
        "#### Context:  \n",
        "In this exercise, you will explore the impact of different distance metrics on the k-Nearest Neighbors (kNN) model's performance. By comparing the test accuracy of the kNN model using various distance metrics, you can identify which metric is most effective for this particular dataset.\n",
        "\n",
        "#### Task:  \n",
        "Implement a Python script to train and evaluate kNN models using different distance metrics. Your goal is to determine which distance metric leads to the highest test accuracy.\n",
        "\n",
        "#### Instructions:  \n",
        "1\\. **Distance Metrics:** Define a list of distance metrics to evaluate – Euclidean, Manhattan, and Cosine.  \n",
        "2\\. **Model Training and Evaluation:** For each distance metric, train a kNN model on the scaled training data and evaluate its accuracy on the scaled test data.  \n",
        "3\\. **Accuracy Comparison:** Store and compare the accuracy scores for each metric to identify the most effective one.\n",
        "\n",
        "#### Question:  \n",
        "Based on the script, which distance metric provides the best test accuracy for the kNN model?"
      ],
      "metadata": {
        "id": "q9CWRKLouIQF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn._____ import accuracy_score # Hint: Import accuracy_score\n",
        "\n",
        "# Defining different distance metrics\n",
        "metrics = ['euclidean', 'manhattan', 'cosine']\n",
        "scores = {}\n",
        "\n",
        "# Training and evaluating a kNN model for each distance metric\n",
        "\n",
        "for metric in ____: # Hint: iterate over the metrics list\n",
        "    knn = KNeighborsClassifier(_____=metric) # Hint: Use metric hyperparam.\n",
        "    knn.fit(X_train_scaled, y_train)\n",
        "    y_pred = knn._____(____) # Hint: make the prediction on test data.\n",
        "    score = accuracy_score(____, ____) # Hint: check the accuracy on the test data predictions.\n",
        "    scores[metric] = score\n",
        "    print(f\"Accuracy with {metric} distance: {score}\")\n",
        "\n",
        "# Determining the best performing metric\n",
        "best_metric = max(scores, key=scores.get)\n",
        "print(f\"The best-performing metric is {best_metric} with an accuracy of {scores[best_metric]}.\")"
      ],
      "metadata": {
        "id": "R0z_aAHVtypp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "## Bias-Variance in kNN\n",
        "\n",
        "#### Context:\n",
        "To understand the bias-variance trade-off in the k-Nearest Neighbors (kNN) algorithm, you'll analyze how kNN's accuracy varies with different k values. By plotting the training and testing accuracies on the same graph, you can visually assess how the model's bias and variance change as the complexity (determined by k) changes.\n",
        "\n",
        "#### Task:\n",
        "Implement Python code to train kNN models with a range of k values and plot the training and testing accuracies on a multi-line graph. This visualization will help you determine the optimal balance between bias and variance.\n",
        "\n",
        "#### Instructions:\n",
        "1. **Initialize Accuracy Lists:** Create two lists, `train_acc` and `test_acc`, to store the accuracies for training and testing sets, respectively.\n",
        "2. **Training and Evaluation Loop:** Iterate k from 1 to 80, train a kNN model using the Manhattan metric for each k using the previously used scaled data, and append the accuracies to the corresponding lists.\n",
        "3. **Plotting:** Use `matplotlib` to create a multi-line plot where the x-axis represents the k values, and the y-axis represents accuracy. Plot both `train_acc` and `test_acc` on this graph to create two distinct lines.\n",
        "4. **Enhancing the Plot:**\n",
        "\t - Add a title to the plot: 'kNN Training and Testing Accuracies'.\n",
        "\t - Label the x-axis as 'Number of Neighbors (k)' and the y-axis as 'Accuracy'.\n",
        "\t - Insert a legend to differentiate between the training and testing accuracy lines.\n",
        "\t - Use different colors for the two lines for clear visualization.\n",
        "\n",
        "#### Question:\n",
        "After visualizing the training and testing accuracies for different k values, how do the trends in the plot help you understand the bias-variance trade-off in kNN?\n",
        "\n"
      ],
      "metadata": {
        "id": "EKQHoTLMuxtK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_acc = ____ # Hint: empty list\n",
        "test_acc = ____ # Hint: empty list\n",
        "\n",
        "for k in _____(1, ___): # Hint: iterate over 1 to 80.\n",
        "    kNN = KNeighborsClassifier(_____=k, metric=____) # Hint: put appropriate hyperparams.\n",
        "    kNN.fit(X_train_scaled, y_train)\n",
        "    train_acc.append(kNN.score(_____, _____)) # Hint: score on Train dataset.\n",
        "    test_acc.append(kNN.score(_____, ____)) # Hint: score on Test dataset.\n",
        "\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.plot(range(1, 81), ____, label='Training Accuracy', marker='o') # Hint: Plot train accuracies.\n",
        "plt.plot(range(1, 81), ____, color='orange', label='Testing Accuracy', marker='x') # Hint: Plot train accuracies.\n",
        "plt.title('kNN Training and Testing Accuracies')\n",
        "plt.xlabel('Number of Neighbors (k)')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "vB9Rgy8QuYGR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n",
        "## kNN Properties\n",
        "\n",
        "#### Context:  \n",
        "The k-Nearest Neighbors (kNN) algorithm is widely used in machine learning for its simplicity and effectiveness. However, it has certain characteristics and challenges, especially related to dimensionality, distance measures, noise, and the choice of k.\n",
        "\n",
        "#### Question:  \n",
        "Which of the following statements is/are correct regarding the kNN algorithm?\n",
        "\n",
        "#### Statements:  \n",
        "S1: As the number of features increases, the requirement for data points increases exponentially.\n",
        "\n",
        "S2: With increasing dimensions, the Euclidean distance loses its significance.\n",
        "\n",
        "S3: kNN is sensitive to noise and has high time complexity, particularly because it does not learn a discriminative function from the training data but uses the entire dataset for prediction.\n",
        "\n",
        "S4: A lower value of k in kNN can lead to overfitting, as the predictions become more sensitive to the noise in the training data.\n",
        "\n",
        "#### Options\n",
        "\n",
        "A] S1, S2, and S3\n",
        "\n",
        "B] S1 and S2\n",
        "\n",
        "C] S1, S3, and S4\n",
        "  \n",
        "D] All of the Statements\n",
        "\n",
        "\n",
        "Note: **Select the correct option in the question link**"
      ],
      "metadata": {
        "id": "CmsH5wg1vfvs"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n",
        "## kNN Properties-Continued\n",
        "\n",
        "#### Context:\n",
        "The k-Nearest Neighbors (kNN) algorithm has unique properties and approaches that address its computational challenges and the peculiarities of its application. Understanding these properties can greatly enhance the effectiveness of kNN in practical scenarios.\n",
        "\n",
        "#### Question:\n",
        "Which of the following statements are correct regarding the properties and characteristics of the kNN algorithm?\n",
        "\n",
        "#### Statements:\n",
        "S1: If our data is large, locality-sensitive hashing (LSH) can be used to map data to a virtual grid, accelerating the kNN search process.\n",
        "\n",
        "S2: kNN can easily handle outlier data by choosing a very high value of k, as it averages the neighbors' responses, potentially diminishing the effect of outliers.\n",
        "\n",
        "S3: kNN is considered a non-parametric method because it does not assume a particular form for the function that describes the relationship between feature and target variables.\n",
        "\n",
        "#### Options\n",
        "   \n",
        "A] S1 and S3\n",
        "   \n",
        "B] S2 only\n",
        "\n",
        "C] S1 only\n",
        "  \n",
        "D] S1, S2, and S3\n",
        "\n",
        "\n",
        "Note: **Select the correct option in the question link**\n"
      ],
      "metadata": {
        "id": "vTrLejWLwDc-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n",
        "## Optimizing kNN with Cross-Validation\n",
        "\n",
        "#### Context:\n",
        "You're tasked with writing Python code to determine the optimal k value for a k-Nearest Neighbors (kNN) classifier using cross-validation. This method will help you understand how different k values influence the model's predictive performance.\n",
        "\n",
        "#### Task:\n",
        "Write a Python script to find the optimal k value for a kNN classifier by testing a range of k values and evaluating their performance using cross-validation. Then, assess the chosen k value's performance on a test set.\n",
        "\n",
        "#### Instructions:\n",
        "1. **Define the Range for k:** Set up a range of k values from 2 to 10.\n",
        "2. **Cross-Validation Loop:** Iterate through the k values, initializing a KNeighborsClassifier for each. Perform 5-fold cross-validation on the scaled training data and compute the mean accuracy for each k.\n",
        "3. **Identify the Best k:** Determine which k value yields the highest mean cross-validation accuracy.\n",
        "4. **Test Set Evaluation:** Train a new kNN model using the best k value on the entire training set. Then, evaluate this model on the test set to obtain the test accuracy.\n",
        "5. **Code Execution:** Execute your script to discover the optimal k value and its corresponding test set accuracy.\n",
        "\n",
        "#### Question:\n",
        "Based on your script execution, which statement correctly describes the outcome for the optimal k value and its test set accuracy?\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "wmIUZFkYwcYo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Array to store mean cross-validation scores\n",
        "mean_cv_scores = []\n",
        "\n",
        "# Define the range of k values to try\n",
        "k_values = np.arange(2, 11)\n",
        "\n",
        "\n",
        "for k in _____: # Hint: # Loop over each value of k\n",
        "\n",
        "    knn = KNeighborsClassifier(______=k, metric=_____) # Hint: Initialize the kNN classifier with the current k value.\n",
        "\n",
        "    cv_scores = cross_val_score(knn, X_train_scaled, y_train, cv=____) # Hint: Perform 5-fold cross-validation.\n",
        "\n",
        "    mean_cv_scores.append(np.mean(______)) # Hint: Calculate the mean of the cross-validation scores.\n",
        "\n",
        "\n",
        "plt.figure(figsize=(8, 6))\n",
        "plt.plot(k_values, ______, marker='o') # Hint: Plotting the mean cross-validation scores for each k value\n",
        "plt.title('Mean Cross-Validation Accuracy vs k')\n",
        "plt.xlabel('Number of Neighbors: k')\n",
        "plt.ylabel('Mean Cross-Validation Accuracy')\n",
        "plt.grid(True)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "qwdY3qHAwlqJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "best_k = ____ # Hint:  Identify the k value with the highest mean cross-validation accuracy from the plot\n",
        "\n",
        "print(f\"The best value of k is: {best_k} with a cross-validation accuracy of: {max(mean_cv_scores):.2f}\")\n",
        "\n",
        "\n",
        "knn_best = KNeighborsClassifier(n_neighbors=best_k, metric='manhattan')\n",
        "knn_best.fit(X_train_scaled, ______)  # Hint: Training the model on train dataset with the best k value\n",
        "test_accuracy = knn_best.score(______, y_test) # Hint: evaluate model performance on the test set\n",
        "print(f\"Test set accuracy with the best k: {test_accuracy}\")"
      ],
      "metadata": {
        "id": "6srWRVTvwo3a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "VNKCAg5qeZKL"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}